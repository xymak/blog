<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on mak&#39;s blog</title>
    <link>https://xymak.github.io/blog/posts/</link>
    <description>Recent content in Posts on mak&#39;s blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 25 May 2020 00:44:54 +0800</lastBuildDate>
    
	<atom:link href="https://xymak.github.io/blog/posts/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>《Go 语言设计与实现》：读书笔记</title>
      <link>https://xymak.github.io/blog/posts/golang-mutex/</link>
      <pubDate>Mon, 25 May 2020 00:44:54 +0800</pubDate>
      
      <guid>https://xymak.github.io/blog/posts/golang-mutex/</guid>
      <description>最近在读《Go 语言设计与实现》的时候，里面提到golang里的互斥锁分正常模式和饥饿模式，饥饿模式是golang 1.9版本引入的优化。饥饿这个次有点抽象，我调研了一下为什么做了这方面的优化。 下面引入一下YiXu Zhang 写的文章
文章里的例子：
func main() { done := make(chan bool, 1) var mu sync.Mutex // goroutine 1  go func() { for { select { case &amp;lt;-done: return default: mu.Lock() time.Sleep(100 * time.Microsecond) mu.Unlock() } } }() // goroutine 2  for i := 0; i &amp;lt; 10; i++ { time.Sleep(100 * time.Microsecond) mu.Lock() mu.Unlock() } done &amp;lt;- true } 如果用golang 1.8运行上面这个例子:
Lock acquired per goroutine: g1: 7200216 g2: 10 互斥锁被第二个协程捕获十次，而第一个协程则捕获了700万次。首先协程1获得锁后睡眠100ms，当协程2尝试获取锁时，它将被添加到锁的队列（FIFO）中，并且进入等待状态。 然后，协程1释放了锁。协程2也被唤醒了，被标记为可运行，然后等待调度器在线程上运行。 但是这个时候协程1又去获得锁。 到协程2去获得锁的时候，发现锁已经被其他线程持有了。 这个问题可以总结为：刚被唤起的协程与在运行的协程竞争时，大概率会获取不到锁。 本身golang 1.</description>
    </item>
    
    <item>
      <title>利用gdb分析nginx core dump文件</title>
      <link>https://xymak.github.io/blog/posts/nginx-core-dump-gdb/</link>
      <pubDate>Sat, 02 May 2020 17:50:57 +0800</pubDate>
      
      <guid>https://xymak.github.io/blog/posts/nginx-core-dump-gdb/</guid>
      <description>今天学习极客时间《Nginx核心知识100讲》，其中介绍了gdb怎么分析nginx的core dump文件。我在这里记录下来。
首先在nginx.conf中加入core dump文件（核心转储文件）的配置，保证nginx对目录有写权限
worker_rlimit_core 90m; working_directory /tmp/nginxcore/; 然后给nginx master发个SIGHUP信号。
kill -1 ${PID} 给其中有一个worker发送SIGSEGV信号，使nginx生成core dump文件.
kill -s SIGSEGV ${PID} 然后通过gdb分析现场。
gdb nginx core GNU gdb (GDB) Red Hat Enterprise Linux 7.6.1-119.el7 Copyright (C) 2013 Free Software Foundation, Inc. License GPLv3+: GNU GPL version 3 or later &amp;lt;http://gnu.org/licenses/gpl.html&amp;gt; This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Type &amp;quot;show copying&amp;quot; and &amp;quot;show warranty&amp;quot; for details.</description>
    </item>
    
    <item>
      <title>今年晋升答辩的时候遇到的问题：etcd怎么添加新节点？</title>
      <link>https://xymak.github.io/blog/posts/etcd/</link>
      <pubDate>Sat, 18 Apr 2020 00:44:54 +0800</pubDate>
      
      <guid>https://xymak.github.io/blog/posts/etcd/</guid>
      <description>我自己搭的etcd集群的时候，随便在网上找了个demo就搞定了，没关注这方面的问题。被评为问到就蒙了。今天我遇到的问题都复盘一遍。
1.etcd怎么添加一个节点？ 我之前没搭建过zookeeper、consul之类的集群，所有没关注过。 被问到这个问题，我当时回答是改配置文件，其实是不行的。因为，因为重新启动启动各个节点的时候，会有一致性问题: 需要重启，如果让数据版本比较旧的节点成为了leader，处理了写入请求后，当其他节点重新加入后，这个节点成为最新版本的节点，数据覆盖了之前的版本.
这个时候要通过etcdctl动态添加。加入本身有3个节点：
etcd --name myetcd1 --listen-client-urls http://0.0.0.0:23791 --advertise-client-urls http://0.0.0.0:23791 --listen-peer-urls http://0.0.0.0:23801 --initial-advertise-peer-urls http://0.0.0.0:23801 --initial-cluster-token etcd-cluster-test --initial-cluster-state new --initial-cluster myetcd1=http://0.0.0.0:23801,myetcd2=http://0.0.0.0:23802,myetcd3=http://0.0.0.0:23803 etcd --name myetcd2 --listen-client-urls http://0.0.0.0:23792 --advertise-client-urls http://0.0.0.0:23792 --listen-peer-urls http://0.0.0.0:23802 --initial-advertise-peer-urls http://0.0.0.0:23802 --initial-cluster-token etcd-cluster-test --initial-cluster-state new --initial-cluster myetcd1=http://0.0.0.0:23801,myetcd2=http://0.0.0.0:23802,myetcd3=http://0.0.0.0:23803 etcd --name myetcd3 --listen-client-urls http://0.0.0.0:23793 --advertise-client-urls http://0.0.0.0:23793 --listen-peer-urls http://0.0.0.0:23803 --initial-advertise-peer-urls http://0.0.0.0:23803 --initial-cluster-token etcd-cluster-test --initial-cluster-state new --initial-cluster myetcd1=http://0.0.0.0:23801,myetcd2=http://0.0.0.0:23802,myetcd3=http://0.0.0.0:23803 查看member列表：
etcdctl --endpoints=http://127.0.0.1:23791 member list 47170e1b92eadb07: name=myetcd1 peerURLs=http://0.0.0.0:23801 clientURLs=http://0.0.0.0:23791 isLeader=true d150980031282a6b: name=myetcd2 peerURLs=http://0.0.0.0:23802 clientURLs=http://0.</description>
    </item>
    
  </channel>
</rss>